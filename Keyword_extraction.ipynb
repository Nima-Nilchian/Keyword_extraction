{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nima-Nilchian/Keyword_extraction/blob/master/Keyword_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXdlZlPAaHMf"
      },
      "source": [
        "# Keyword Extraction\n",
        "\n",
        "# استخراج عبارت‌های کلیدی متن"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyUqG5oGVktL"
      },
      "source": [
        "<p align=\"right\">\n",
        "ارزیابی روش‌ها مورد استفاده قرار خواهد گرفت. علاوه بر گزارش نتایج برای هر یک از روش‌ها با استفاده از مجموعه داده، نمونه‌هایی از خروجی را هم برای هر روش گزارش کرده و به صورت شهودی نیز مقایسه‌ای انجام دهید. همچنین سرعت روش‌های پیاده‌سازی شده نیز نیاز به مقایسه دارد.\n",
        "</p>\n",
        "<p align=\"right\">\n",
        ":روش‌های زیر را پیاده‌سازی و طبق روال بالا ارزیابی و مقایسه کنید\n",
        "</p>\n",
        "\n",
        "*   baseline (TF-IDF)\n",
        "*   TF-IDF with Ngrams\n",
        "*   TF-IDF with chunking\n",
        "*   KP-Miner\n",
        "*   Yake\n",
        "*   TextRank\n",
        "*   SingleRank\n",
        "*   TopicRank\n",
        "*   TopicalPageRank\n",
        "*   PositionRank\n",
        "*   MultipartiteRank\n",
        "*   scake\n",
        "*   sgrank\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OhOIh7UbHh6"
      },
      "source": [
        "# Reading and preproccessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7HKTRH57yfI"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/boudinfl/pke.git\n",
        "!pip install perke\n",
        "!python -m perke download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "sDISdg5ibZuX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import string\n",
        "import perke\n",
        "import time\n",
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hIA0d1k-bO_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008bd6fd-dc48-484e-8406-486c4a664c6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at ./content\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"./content\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lRg3zK-bcxL6"
      },
      "outputs": [],
      "source": [
        "data_loc = './content/MyDrive/datasets/ke/ke_dataset.txt'\n",
        "\n",
        "df = pd.DataFrame()\n",
        "with open(data_loc, 'r') as f:\n",
        "  for line in f.readlines():\n",
        "    json_data = json.loads(line.strip())\n",
        "    df = pd.concat([df, pd.DataFrame([json_data])], ignore_index=True)\n",
        "\n",
        "df.drop('id', axis=1, inplace=True)\n",
        "all_texts = df['body'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHe8wivuhvkY",
        "outputId": "36fc8f5d-ce4c-412c-e6fa-a098fc87ef84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 450 entries, 0 to 449\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   body      450 non-null    object\n",
            " 1   keywords  450 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 7.2+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ke_topicRank(text):\n",
        "  valid_pos_tags = {'NOUN', 'ADJ'}\n",
        "  extractor = perke.unsupervised.graph_based.TopicRank(valid_pos_tags=valid_pos_tags)\n",
        "\n",
        "  extractor.load_text(input=text, word_normalization_method='lemmatization')\n",
        "  extractor.select_candidates()\n",
        "  extractor.weight_candidates(\n",
        "      threshold=0.74, metric='jaccard', linkage_method='average')\n",
        "\n",
        "  keyphrases = extractor.get_n_best(n=10)\n",
        "  candids, score = zip(*keyphrases)\n",
        "\n",
        "  return list(candids)\n",
        "\n",
        "\n",
        "def ke_textRank(text):\n",
        "  valid_pos_tags = {'NOUN', 'ADJ'}\n",
        "  extractor = perke.unsupervised.graph_based.TextRank(valid_pos_tags=valid_pos_tags)\n",
        "\n",
        "  extractor.load_text(text, word_normalization_method='lemmatization')\n",
        "  extractor.weight_candidates(window_size=2, top_t_percent=0.33)\n",
        "\n",
        "  keyphrases = extractor.get_n_best(n=10)\n",
        "  candids, score = zip(*keyphrases)\n",
        "\n",
        "  return list(candids)\n",
        "\n",
        "\n",
        "def ke_singleRank(text):\n",
        "  valid_pos_tags = {'NOUN', 'ADJ'}\n",
        "  extractor = perke.unsupervised.graph_based.SingleRank(valid_pos_tags=valid_pos_tags)\n",
        "\n",
        "  extractor.load_text(input=text, word_normalization_method='lemmatization')\n",
        "  extractor.select_candidates()\n",
        "  extractor.weight_candidates(window=10)\n",
        "\n",
        "  keyphrases = extractor.get_n_best(n=10)\n",
        "  candids, score = zip(*keyphrases)\n",
        "\n",
        "  return list(candids)\n",
        "\n",
        "\n",
        "def ke_positionRank(text):\n",
        "  # Define the grammar for selecting the keyphrase candidates\n",
        "  grammar = r\"\"\"\n",
        "      NP:\n",
        "          {<NOUN>}<VERB>\n",
        "      NP:\n",
        "          {<DET(,EZ)?|NOUN(,EZ)?|NUM(,EZ)?|ADJ(,EZ)|PRON><DET(,EZ)|NOUN(,EZ)|NUM(,EZ)|ADJ(,EZ)|PRON>*}\n",
        "          <NOUN>}{<.*(,EZ)?>\n",
        "  \"\"\"\n",
        "  valid_pos_tags = {'NOUN', 'NOUN,EZ', 'ADJ', 'ADJ,EZ'}\n",
        "  extractor = perke.unsupervised.graph_based.PositionRank(valid_pos_tags=valid_pos_tags)\n",
        "\n",
        "  extractor.load_text(\n",
        "      input=text, word_normalization_method='stemming',\n",
        "      universal_pos_tags=False,\n",
        "  )\n",
        "  extractor.select_candidates(grammar=grammar, maximum_word_number=3)\n",
        "  extractor.weight_candidates(window_size=10)\n",
        "\n",
        "  keyphrases = extractor.get_n_best(n=n)\n",
        "  candids, score = zip(*keyphrases)\n",
        "\n",
        "  return list(candids)\n",
        "\n",
        "\n",
        "def ke_multipartiteRank(text):\n",
        "  valid_pos_tags = {'NOUN', 'ADJ'}\n",
        "  extractor = perke.unsupervised.graph_based.MultipartiteRank(valid_pos_tags=valid_pos_tags)\n",
        "\n",
        "  extractor.load_text(input=text, word_normalization_method='stemming')\n",
        "  extractor.select_candidates()\n",
        "  extractor.weight_candidates(\n",
        "      threshold=0.74,\n",
        "      metric='jaccard',\n",
        "      linkage_method='average',\n",
        "      alpha=1.1,\n",
        "  )\n",
        "\n",
        "  keyphrases = extractor.get_n_best(n=n)\n",
        "  candids, score = zip(*keyphrases)\n",
        "\n",
        "  return list(candids)"
      ],
      "metadata": {
        "id": "YToHOv9RstT1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of processes to run in parallel\n",
        "num_processes = multiprocessing.cpu_count()\n",
        "\n",
        "# Create a multiprocessing pool\n",
        "pool = multiprocessing.Pool(processes=num_processes)\n",
        "\n",
        "# Perform keyword extraction for each text using multiprocessing\n",
        "results_topic = pool.map(ke_topicRank, all_texts[:25])\n",
        "results_text = pool.map(ke_textRank, all_texts[:25])\n",
        "results_single = pool.map(ke_singleRank, all_texts[:25])\n",
        "results_position = pool.map(ke_positionRank, all_texts[:25])\n",
        "results_multi = pool.map(ke_multipartiteRank, all_texts[:25])\n",
        "\n",
        "# Close the pool of processes\n",
        "pool.close()\n",
        "pool.join()"
      ],
      "metadata": {
        "id": "yA7EbSfwur0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(candidates, references):\n",
        "    r = len(set(references) & set(candidates)) / len(set(references))\n",
        "    p = len(set(references) & set(candidates)) / len(set(candidates))\n",
        "\n",
        "    if p == 0 or r == 0:\n",
        "      return 0\n",
        "\n",
        "    return (2*p*r) / (p+r)"
      ],
      "metadata": {
        "id": "KHaHuIdhscif"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topicRank= []\n",
        "textRank = []\n",
        "singleRank = []\n",
        "positionRank = []\n",
        "multi = []\n",
        "\n",
        "for i in range(len(results_topic)):\n",
        "  references = df['keywords'].iloc[i]\n",
        "  topicRank.append(evaluate(results_topic[i], references))\n",
        "  textRank.append(evaluate(results_text[i], references))\n",
        "  singleRank.append(evaluate(results_single[i], references))\n",
        "  positionRank.append(evaluate(results_position[i], references))\n",
        "  multi.append(evaluate(results_multi[i], references))\n",
        "\n",
        "print(\"Topic_Rank f1 score is:\", topicRank)\n",
        "print(\"Text_Rank f1 score is:\", textRank)\n",
        "print(\"Single_Rank f1 score is:\", singleRank)\n",
        "print(\"Position_Rank f1 score is:\", positionRank)\n",
        "print(\"Multipartite_Rank f1 score is:\", multi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTZsrO4TsgqI",
        "outputId": "1b2ee99e-5c02-4233-f796-743675413fff"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic_Rank f1 score is: [0.125, 0, 0, 0.11111111111111112, 0.125, 0, 0.14285714285714288, 0.26666666666666666, 0.11111111111111112, 0.10000000000000002, 0.22222222222222224, 0, 0, 0.11764705882352941, 0.13333333333333333, 0.25, 0.125, 0.13333333333333333, 0.125, 0, 0, 0.2105263157894737, 0, 0.1904761904761905, 0]\n",
            "Text_Rank f1 score is: [0, 0, 0.15384615384615383, 0.11111111111111112, 0.125, 0.14285714285714288, 0.14285714285714288, 0, 0.11111111111111112, 0.10000000000000002, 0.11111111111111112, 0, 0, 0, 0, 0, 0.125, 0.13333333333333333, 0.25, 0.13333333333333333, 0, 0, 0, 0, 0.26666666666666666]\n",
            "Single_Rank f1 score is: [0, 0, 0.15384615384615383, 0.11111111111111112, 0.125, 0.28571428571428575, 0, 0, 0, 0.10000000000000002, 0.11111111111111112, 0, 0, 0, 0.26666666666666666, 0, 0.125, 0, 0.125, 0.13333333333333333, 0, 0, 0, 0.09523809523809525, 0.13333333333333333]\n",
            "Position_Rank f1 score is: [0, 0, 0.15384615384615383, 0, 0, 0.14285714285714288, 0, 0.13333333333333333, 0.22222222222222224, 0.10000000000000002, 0, 0.14285714285714288, 0, 0, 0, 0, 0, 0.13333333333333333, 0, 0, 0, 0, 0.125, 0, 0]\n",
            "Multipartite_Rank f1 score is: [0.25, 0, 0, 0.11111111111111112, 0.125, 0, 0.14285714285714288, 0.26666666666666666, 0.11111111111111112, 0.20000000000000004, 0.33333333333333326, 0, 0.125, 0.11764705882352941, 0.13333333333333333, 0.37499999999999994, 0.25, 0.13333333333333333, 0.125, 0, 0, 0.2105263157894737, 0, 0.28571428571428564, 0.26666666666666666]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_mean_f1 = np.mean(np.array(topicRank))\n",
        "text_mean_f1 = np.mean(np.array(textRank))\n",
        "single_mean_f1 = np.mean(np.array(singleRank))\n",
        "position_mean_f1 = np.mean(np.array(positionRank))\n",
        "multi_mean_f1 = np.mean(np.array(multi))\n",
        "\n",
        "print(\"Topic Rank mean f1 score is:\", topic_mean_f1.round(4))\n",
        "print(\"Text Rank mean f1 score is:\", text_mean_f1.round(4))\n",
        "print(\"Single Rank mean f1 score is:\", single_mean_f1.round(4))\n",
        "print(\"Position Rank mean f1 score is:\", position_mean_f1.round(4))\n",
        "print(\"Multipartite Rank mean f1 score is:\", multi_mean_f1.round(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVRyCjgR1ODR",
        "outputId": "7d8d1420-48f3-44a8-f282-102a3d2cf917"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic Rank mean f1 score is: 0.0996\n",
            "Text Rank mean f1 score is: 0.0762\n",
            "Single Rank mean f1 score is: 0.0706\n",
            "Position Rank mean f1 score is: 0.0461\n",
            "Multipartite Rank mean f1 score is: 0.1425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Alz7qemfxThF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+ZUjmdJ0h/uEG1bcze9bl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}