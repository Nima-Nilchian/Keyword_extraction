{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nima-Nilchian/Keyword_extraction/blob/master/Keyword_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXdlZlPAaHMf"
      },
      "source": [
        "# Keyword Extraction\n",
        "\n",
        "# استخراج عبارت‌های کلیدی متن"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyUqG5oGVktL"
      },
      "source": [
        "<p align=\"right\">\n",
        "ارزیابی روش‌ها مورد استفاده قرار خواهد گرفت. علاوه بر گزارش نتایج برای هر یک از روش‌ها با استفاده از مجموعه داده، نمونه‌هایی از خروجی را هم برای هر روش گزارش کرده و به صورت شهودی نیز مقایسه‌ای انجام دهید. همچنین سرعت روش‌های پیاده‌سازی شده نیز نیاز به مقایسه دارد.\n",
        "</p>\n",
        "<p align=\"right\">\n",
        ":روش‌های زیر را پیاده‌سازی و طبق روال بالا ارزیابی و مقایسه کنید\n",
        "</p>\n",
        "\n",
        "*   baseline (TF-IDF)\n",
        "*   TF-IDF with Ngrams\n",
        "*   TF-IDF with chunking\n",
        "*   KP-Miner\n",
        "*   Yake\n",
        "*   TextRank\n",
        "*   SingleRank\n",
        "*   TopicRank\n",
        "*   TopicalPageRank\n",
        "*   PositionRank\n",
        "*   MultipartiteRank\n",
        "*   scake\n",
        "*   sgrank\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OhOIh7UbHh6"
      },
      "source": [
        "# Reading and preproccessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7HKTRH57yfI"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/boudinfl/pke.git\n",
        "!pip install perke\n",
        "!python -m perke download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sDISdg5ibZuX"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import string\n",
        "import perke"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIA0d1k-bO_c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"./content\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRg3zK-bcxL6"
      },
      "outputs": [],
      "source": [
        "data_loc = './content/MyDrive/datasets/ke/ke_dataset.txt'\n",
        "\n",
        "df = pd.DataFrame()\n",
        "with open(data_loc, 'r') as f:\n",
        "  for line in f.readlines():\n",
        "    json_data = json.loads(line.strip())\n",
        "    df = pd.concat([df, pd.DataFrame([json_data])], ignore_index=True)\n",
        "\n",
        "df.drop('id', axis=1, inplace=True)\n",
        "all_texts = df['body'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHe8wivuhvkY",
        "outputId": "7382c8f1-ebe1-46c6-ebf7-d1e1c4ace31f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 450 entries, 0 to 449\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   body      450 non-null    object\n",
            " 1   keywords  450 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 7.2+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ke_textRank(text, n=10):\n",
        "  extractor = perke.unsupervised.graph_based.TextRank()\n",
        "\n",
        "  extractor.load_text(text, word_normalization_method='lemmatization')\n",
        "  extractor.weight_candidates(window_size=2, top_t_percent=0.33)\n",
        "\n",
        "  keyphrases = extractor.get_n_best(n=n)\n",
        "  candids, score = zip(*keyphrases)\n",
        "  return list(candids)\n",
        "\n",
        "def ke_topicRank(text, n=10):\n",
        "  valid_pos_tags = {'NOUN', 'ADJ'}\n",
        "  extractor = perke.unsupervised.graph_based.TopicRank(valid_pos_tags=valid_pos_tags)\n",
        "\n",
        "  extractor.load_text(input=text, word_normalization_method='lemmatization')\n",
        "  extractor.select_candidates()\n",
        "  extractor.weight_candidates(\n",
        "      threshold=0.74, metric='jaccard', linkage_method='average')\n",
        "\n",
        "  keyphrases = extractor.get_n_best(n=n)\n",
        "  candids, score = zip(*keyphrases)\n",
        "  return list(candids)\n",
        "\n",
        "def ke_singleRank(text, n=10):\n",
        "  valid_pos_tags = {'NOUN', 'ADJ'}\n",
        "  extractor = perke.unsupervised.graph_based.SingleRank(valid_pos_tags=valid_pos_tags)\n",
        "\n",
        "  extractor.load_text(input=text, word_normalization_method='lemmatization')\n",
        "  extractor.select_candidates()\n",
        "  extractor.weight_candidates(window=10)\n",
        "\n",
        "  keyphrases = extractor.get_n_best(n=n)\n",
        "  candids, score = zip(*keyphrases)\n",
        "  return list(candids)\n",
        "\n",
        "\n",
        "def ke_positionRank(text, n):\n",
        "  # Define the grammar for selecting the keyphrase candidates\n",
        "  grammar = r\"\"\"\n",
        "      NP:\n",
        "          {<NOUN>}<VERB>\n",
        "      NP:\n",
        "          {<DET(,EZ)?|NOUN(,EZ)?|NUM(,EZ)?|ADJ(,EZ)|PRON><DET(,EZ)|NOUN(,EZ)|NUM(,EZ)|ADJ(,EZ)|PRON>*}\n",
        "          <NOUN>}{<.*(,EZ)?>\n",
        "  \"\"\"\n",
        "\n",
        "  valid_pos_tags = {'NOUN', 'NOUN,EZ', 'ADJ', 'ADJ,EZ'}\n",
        "  extractor = perke.unsupervised.graph_based.PositionRank(valid_pos_tags=valid_pos_tags)\n",
        "\n",
        "  extractor.load_text(\n",
        "      input=text, word_normalization_method='stemming',\n",
        "      universal_pos_tags=False,\n",
        "  )\n",
        "  extractor.select_candidates(grammar=grammar, maximum_word_number=3)\n",
        "  extractor.weight_candidates(window_size=10)\n",
        "\n",
        "  keyphrases = extractor.get_n_best(n=n)\n",
        "  candids, score = zip(*keyphrases)\n",
        "  return list(candids)\n",
        "\n",
        "\n",
        "def ke_multipartiteRank(text, n):\n",
        "  valid_pos_tags = {'NOUN', 'ADJ'}\n",
        "  extractor = perke.unsupervised.graph_based.MultipartiteRank(valid_pos_tags=valid_pos_tags)\n",
        "\n",
        "  extractor.load_text(input=text, word_normalization_method='stemming')\n",
        "  extractor.select_candidates()\n",
        "  extractor.weight_candidates(\n",
        "      threshold=0.74,\n",
        "      metric='jaccard',\n",
        "      linkage_method='average',\n",
        "      alpha=1.1,\n",
        "  )\n",
        "\n",
        "  keyphrases = extractor.get_n_best(n=n)\n",
        "  candids, score = zip(*keyphrases)\n",
        "  return list(candids)"
      ],
      "metadata": {
        "id": "YToHOv9RstT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topicRank_keywords = []\n",
        "textRank_keywords = []\n",
        "singleRank_keywords = []\n",
        "positionRank_keywords = []\n",
        "multi_keywords = []\n",
        "\n",
        "n = 10\n",
        "for i, text in enumerate(all_texts[:20]):\n",
        "\n",
        "  topicRank_keywords.append(ke_topicRank(text, n))\n",
        "  textRank_keywords.append(ke_textRank(text, n))\n",
        "  singleRank_keywords.append(ke_textRank(text, n))\n",
        "  positionRank_keywords.append(ke_positionRank(text, n))\n",
        "  multi_keywords.append(ke_multipartiteRank(text, n))\n",
        "\n"
      ],
      "metadata": {
        "id": "yA7EbSfwur0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_recall(candidates, references):\n",
        "    return len(set(references) & set(candidates)) / len(set(references))\n",
        "\n",
        "def calculate_percission(candidates, references):\n",
        "  return len(set(references) & set(candidates) / len(candidates))\n",
        "\n",
        "topicRank_recall, topic_percision= [], []\n",
        "textRank_recall, text_percision = [], []\n",
        "singleRank_recall, single_percision = [], []\n",
        "positionRank_recall, position_percision = [], []\n",
        "multi_recall, multi_percision = [], []\n",
        "\n",
        "for i in range(len(topicRank_keywords)):\n",
        "  references = df['keywords'].iloc[i]\n",
        "  topicRank_recall.append(calculate_recall(topicRank_keywords[i], references))\n",
        "  topic_percision.append(calculate_recall(topicRank_keywords[i], references))\n",
        "\n",
        "  textRank_recall.append(calculate_recall(textRank_keywords[i], references))\n",
        "  text_percision.append(calculate_recall(textRank_keywords[i], references))\n",
        "\n",
        "  singleRank_recall.append(calculate_recall(singleRank_keywords[i], references))\n",
        "  single_percision.append(calculate_recall(singleRank_keywords[i], references))\n",
        "\n",
        "  positionRank_recall.append(calculate_recall(positionRank_keywords[i], references))\n",
        "  position_percision.append(calculate_recall(positionRank_keywords[i], references))\n",
        "\n",
        "  multi_recall.append(calculate_recall(multi_keywords[i], references))\n",
        "  multi_percision.append(calculate_recall(multi_keywords[i], references))\n",
        "\n",
        "\n",
        "print(\"Topic Rank recall score is:\", topicRank_recall)\n",
        "print(\"Topic Rank recall score is:\", topic_percision)\n",
        "\n",
        "print(\"Text Rank recall score is:\", textRank_recall)\n",
        "print(\"Text Rank recall score is:\", text_percision)\n",
        "\n",
        "print(\"Single Rank recall score is:\", singleRank_recall)\n",
        "print(\"Single Rank recall score is:\", single_percision)\n",
        "\n",
        "print(\"Position Rank recall score is:\", positionRank_recall)\n",
        "print(\"Position Rank recall score is:\", position_percision)\n",
        "\n",
        "print(\"Multipartite Rank recall score is:\", multi_recall)\n",
        "print(\"Multipartite Rank recall score is:\", multi_percision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "tzUr4LulIuKn",
        "outputId": "88160d31-fbb3-4156-c463-354a437c583e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cfb2f5d179a0>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmulti_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_percision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopicRank_keywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mreferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keywords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mtopicRank_recall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopicRank_keywords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'topicRank_keywords' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "46JRy9zASaJG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjEcB/Izp8q0kXKJWNmyIF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}